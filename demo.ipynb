{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf614ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "import time\n",
    "from keras.api.models import load_model\n",
    "import librosa\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b1d731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      "   1 Microphone Array (Realtek(R) Au, MME (2 in, 0 out)\n",
      "   2 Mezcla estéreo (Realtek(R) Audi, MME (2 in, 0 out)\n",
      "   3 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "   4 Speaker / Headphone (Realtek(R), MME (0 in, 2 out)\n",
      "   5 Primary Sound Capture Driver, Windows DirectSound (2 in, 0 out)\n",
      "   6 Microphone Array (Realtek(R) Audio), Windows DirectSound (2 in, 0 out)\n",
      "   7 Mezcla estéreo (Realtek(R) Audio), Windows DirectSound (2 in, 0 out)\n",
      "   8 Primary Sound Driver, Windows DirectSound (0 in, 2 out)\n",
      "   9 Speaker / Headphone (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "  10 Speaker / Headphone (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "  11 Mezcla estéreo (Realtek(R) Audio), Windows WASAPI (2 in, 0 out)\n",
      "  12 Microphone Array (Realtek(R) Audio), Windows WASAPI (2 in, 0 out)\n",
      "  13 Auriculares con micrófono (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Redmi Buds 6 Lite)), Windows WDM-KS (0 in, 1 out)\n",
      "  14 Auriculares con micrófono (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Redmi Buds 6 Lite)), Windows WDM-KS (1 in, 0 out)\n",
      "  15 Speakers (Realtek HD Audio output), Windows WDM-KS (0 in, 2 out)\n",
      "  16 Mezcla estéreo (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  17 Varios micrófonos (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  18 Auriculares (), Windows WDM-KS (0 in, 2 out)\n",
      "  19 Auriculares con micrófono (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Mixcder E9)), Windows WDM-KS (0 in, 1 out)\n",
      "  20 Auriculares con micrófono (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Mixcder E9)), Windows WDM-KS (1 in, 0 out)\n",
      "  21 Auriculares (), Windows WDM-KS (0 in, 2 out)\n",
      "  22 Auriculares con micrófono (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(T19)), Windows WDM-KS (0 in, 1 out)\n",
      "  23 Auriculares con micrófono (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(T19)), Windows WDM-KS (1 in, 0 out)\n",
      "  24 Auriculares (), Windows WDM-KS (0 in, 2 out)\n"
     ]
    }
   ],
   "source": [
    "print(sd.query_devices())  \n",
    "sd.default.device = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dbfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de grabación\n",
    "SAMPLE_RATE = 16000  # Hz\n",
    "CHANNELS = 1\n",
    "DURATION = 10       # segundos\n",
    "REQUIRED_FRAMES = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Cola para almacenar chunks de audio\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Cargar modelo (opcional, si quieres predecir)\n",
    "model = load_model(\"models/cnn_chroma_0.1107.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1737662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "def normalize(X):\n",
    "    return (X - np.mean(X)) / np.std(X)\n",
    "\n",
    "def sub_extra_column(X):\n",
    "    return X[:, :, :-1]\n",
    "\n",
    "def transpose(X):\n",
    "    return X.transpose(0, 2, 1)\n",
    "\n",
    "# Definición del pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('normalize', FunctionTransformer(normalize, validate=False)),  # Normalización\n",
    "    ('scale', MinMaxScaler(feature_range=(0, 1))),                  # Escalado\n",
    "    ('sub_column', FunctionTransformer(sub_extra_column, validate=False)),  # Quitar columna\n",
    "    ('transpose', FunctionTransformer(transpose, validate=False)),  # Transponer\n",
    "])\n",
    "\n",
    "# Aplicar el pipeline\n",
    "def process_and_encode(X):\n",
    "    # Reshape para MinMaxScaler (flatten y restaurar)\n",
    "    X = preprocessing_pipeline.named_steps['normalize'].transform(X)\n",
    "    X = preprocessing_pipeline.named_steps['scale'].fit_transform(X.reshape(X.shape[0], -1)).reshape(X.shape)\n",
    "    X = preprocessing_pipeline.named_steps['sub_column'].transform(X)\n",
    "    X = preprocessing_pipeline.named_steps['transpose'].transform(X)\n",
    "    \n",
    "    # Predicción con el encoder\n",
    "    encoder = load_model('models/encoders/encoder_chroma.keras')\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    XC = encoder.predict(X)\n",
    "    return XC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ae8f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_callback(indata, frames, time_info, status):\n",
    "    \"\"\"Callback de sonido: añade datos a la cola\"\"\"\n",
    "    if status:\n",
    "        print(f\"Status: {status}\", flush=True)\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def grabar_intervalos():\n",
    "    \"\"\"Graba intervalos de DURATION segundos, extrae chroma y pasa al modelo\"\"\"\n",
    "    with sd.InputStream(samplerate=SAMPLE_RATE,\n",
    "                        channels=CHANNELS,\n",
    "                        callback=audio_callback):\n",
    "        print(\"Grabando en bucle...\")\n",
    "        while True:\n",
    "            audio = sd.rec(int(SAMPLE_RATE*DURATION), samplerate=SAMPLE_RATE,\n",
    "                   channels=CHANNELS, dtype='float32')\n",
    "            sd.wait()\n",
    "            audio = audio.flatten()\n",
    "            \n",
    "            # Extraer características Chroma (n_fft y hop_length para ~313 frames)\n",
    "            chroma = librosa.feature.chroma_stft(\n",
    "                y=audio,\n",
    "                sr=SAMPLE_RATE,\n",
    "            )  # shape = (12, ~313)\n",
    "            print(f\"Chroma extraída: {chroma.shape}\")\n",
    "\n",
    "            # Add a dimension at the beginning to match the model input shape (1, 12, T)\n",
    "            chroma = chroma[np.newaxis, ...]\n",
    "            print(f\"Chroma reshaped: {chroma.shape}\")\n",
    "\n",
    "            chroma = process_and_encode(chroma)\n",
    "            print(chroma.shape)\n",
    "            \n",
    "            # (Opcional) Predecir con el modelo\n",
    "            x = chroma[..., np.newaxis]  # reshape a (1, 12, T, 1)\n",
    "            resultado = model.predict(x)\n",
    "            print(f\"Predicción del modelo: {resultado}\\n\")\n",
    "            \n",
    "            # Breve pausa antes del siguiente intervalo\n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando grabación de intervalos de 10 s...\")\n",
    "    grabar_intervalos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
